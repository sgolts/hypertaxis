{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a58dc9fc-f71c-4233-bfe7-1fac396d6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam \n",
    "import pandas as pd\n",
    "import mappy as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab70f76-735a-4370-882e-e0893ecb84da",
   "metadata": {},
   "source": [
    "# Set up reference genomes (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d92bacb-6acf-4c6f-9dd9-4d2b909eb9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "CPU times: user 1min 32s, sys: 11.1 s, total: 1min 43s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cast_path = \"/nfs/turbo/umms-indikar/shared/projects/poreC/data/references/fasta/Mus_musculus_casteij.CAST_EiJ_v1.dna.toplevel.fa\"\n",
    "cast_ref = mp.Aligner(cast_path)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df3df152-7285-403b-b916-375fb87a707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "CPU times: user 1min 32s, sys: 10.6 s, total: 1min 43s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s129_path = \"/nfs/turbo/umms-indikar/shared/projects/poreC/data/references/fasta/Mus_musculus_129s1svimj.129S1_SvImJ_v1.dna.toplevel.fa\"\n",
    "s129_ref = mp.Aligner(s129_path)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca8450-f1c4-44b9-8b38-a26611598d25",
   "metadata": {},
   "source": [
    "# Monomer Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe33c3bc-6b9d-41af-8c97-65b17dd36259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_and_classify_read(read, ref1_aligner, ref2_aligner, min_mapq=20):\n",
    "    \"\"\"\n",
    "    Aligns a single read against two references and returns its classification.\n",
    "    Handles reads with no sequence.\n",
    "    \"\"\"\n",
    "    seq = read.query_sequence\n",
    "    \n",
    "    # If the read has no sequence, classify as unmapped and return\n",
    "    if not seq:\n",
    "        return \"unmapped\", read\n",
    "\n",
    "    # Align to both references\n",
    "    hits1 = list(ref1_aligner.map(seq))\n",
    "    hits2 = list(ref2_aligner.map(seq))\n",
    "\n",
    "    # Get the best alignment for each reference\n",
    "    best_hit1 = max(hits1, key=lambda hit: getattr(hit, 'score', 0), default=None)\n",
    "    best_hit2 = max(hits2, key=lambda hit: getattr(hit, 'score', 0), default=None)\n",
    "\n",
    "    # Extract alignment metrics\n",
    "    mapq1 = getattr(best_hit1, 'mapq', 0)\n",
    "    score1 = getattr(best_hit1, 'score', 0)\n",
    "    nm1 = getattr(best_hit1, 'NM', float('inf'))\n",
    "\n",
    "    mapq2 = getattr(best_hit2, 'mapq', 0)\n",
    "    score2 = getattr(best_hit2, 'score', 0)\n",
    "    nm2 = getattr(best_hit2, 'NM', float('inf'))\n",
    "\n",
    "    # Classification logic\n",
    "    is_mapped1 = mapq1 >= min_mapq\n",
    "    is_mapped2 = mapq2 >= min_mapq\n",
    "\n",
    "    classification = \"unmapped\" # Default classification\n",
    "    if is_mapped1 and not is_mapped2:\n",
    "        classification = \"haplotype1\"\n",
    "    elif not is_mapped1 and is_mapped2:\n",
    "        classification = \"haplotype2\"\n",
    "    elif is_mapped1 and is_mapped2:\n",
    "        if score1 > score2 and nm1 < nm2:\n",
    "            classification = \"haplotype1\"\n",
    "        elif score2 > score1 and nm2 < nm1:\n",
    "            classification = \"haplotype2\"\n",
    "        else:\n",
    "            classification = \"ambiguous\"\n",
    "            \n",
    "    return classification, read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9882cbd-9261-489f-8e8f-55c1538243e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bam_file(input_bam_path, ref1_aligner, ref2_aligner, output_bam_path, region=None):\n",
    "    \"\"\"\n",
    "    Processes a BAM file, creating an index if needed. Classifies and tags \n",
    "    reads, writes to a new BAM file, and prints summary statistics.\n",
    "    \"\"\"\n",
    "    # Check for BAM index and create if it doesn't exist\n",
    "    if region and not os.path.exists(input_bam_path + \".bai\"):\n",
    "        print(f\"BAM index not found. Creating index for {input_bam_path}...\")\n",
    "        pysam.index(input_bam_path)\n",
    "        print(\"Index created.\")\n",
    "\n",
    "    # Initialize stats counters\n",
    "    stats = {\n",
    "        \"haplotype1\": 0,\n",
    "        \"haplotype2\": 0,\n",
    "        \"ambiguous\": 0,\n",
    "        \"unmapped\": 0,\n",
    "        \"total\": 0\n",
    "    }\n",
    "\n",
    "    with pysam.AlignmentFile(input_bam_path, \"rb\", check_sq=False) as infile:\n",
    "        header = infile.header\n",
    "        classification_map = {\n",
    "            \"haplotype1\": 1,\n",
    "            \"haplotype2\": 2,\n",
    "            \"ambiguous\": 3,\n",
    "            \"unmapped\": 0\n",
    "        }\n",
    "\n",
    "        with pysam.AlignmentFile(output_bam_path, \"wb\", header=header) as outfile:\n",
    "            reads_to_process = infile.fetch(region=region) if region else infile\n",
    "\n",
    "            for read in reads_to_process:\n",
    "                classification, classified_read = align_and_classify_read(read, ref1_aligner, ref2_aligner)\n",
    "                \n",
    "                # Update stats\n",
    "                stats[classification] += 1\n",
    "                stats[\"total\"] += 1\n",
    "                \n",
    "                classified_read.set_tag('HP', classification_map.get(classification, 0), 'i')\n",
    "                outfile.write(classified_read)\n",
    "\n",
    "    print(f\"Processing complete. Tagged BAM file saved to '{output_bam_path}'\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n--- Classification Summary ---\")\n",
    "    if stats[\"total\"] > 0:\n",
    "        for key, value in stats.items():\n",
    "            if key == \"total\":\n",
    "                print(f\"Total Reads Processed: {value}\")\n",
    "            else:\n",
    "                percentage = (value / stats[\"total\"]) * 100\n",
    "                print(f\"{key.capitalize():<12}: {value:>8} ({percentage:.2f}%)\")\n",
    "    else:\n",
    "        print(\"No reads were processed.\")\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa6a85-c670-4f10-81d3-ca2edb1fb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bam = \"/nfs/turbo/umms-indikar/shared/projects/poreC/pipeline_outputs/population/library/merged.bam\"\n",
    "output_bam_chr7 = \"classified_reads_all_tagged.bam\"\n",
    "\n",
    "# Process only chromosome 7\n",
    "process_bam_file(input_bam, s129_ref, cast_ref, output_bam_chr7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b46ec4f2-7765-43ad-86d3-ffdbb79d9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def align_monomer(seq: str, ref, name = None) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Align one query sequence to a mappy index and return a DataFrame of hits.\n",
    "#     Columns match common mappy.AlignedSegment fields.\n",
    "#     \"\"\"\n",
    "#     rows = []\n",
    "#     for hit in ref.map(seq):  # iterate alignments\n",
    "#         rows.append({\n",
    "#             \"ctg\": hit.ctg,                 # reference contig\n",
    "#             \"r_st\": hit.r_st,               # ref start (0-based)\n",
    "#             \"r_en\": hit.r_en,               # ref end (exclusive)\n",
    "#             \"q_st\": getattr(hit, \"q_st\", None),\n",
    "#             \"q_en\": getattr(hit, \"q_en\", None),\n",
    "#             \"strand\": \"-\" if getattr(hit, \"strand\", 1) < 0 else \"+\",\n",
    "#             \"mapq\": getattr(hit, \"mapq\", None),\n",
    "#             \"score\": getattr(hit, \"score\", None),\n",
    "#             \"mlen\": getattr(hit, \"mlen\", None),   # matched length\n",
    "#             \"blen\": getattr(hit, \"blen\", None),   # alignment block length\n",
    "#             \"NM\": getattr(hit, \"NM\", None),       # edits if available\n",
    "#             \"is_primary\": bool(getattr(hit, \"is_primary\", True)),\n",
    "#             \"cigar\": getattr(hit, \"cigar_str\", None),\n",
    "#             \"name\" : name, \n",
    "#         })\n",
    "#     return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe1fd384-de4c-49ea-acab-a86578ae2813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "read.qname='52aab340-35f0-4a9a-b718-b3381a32c138'\n",
      "  ctg    r_st    r_en  q_st  q_en strand  mapq score  mlen  blen  NM  \\\n",
      "0   1    2354    2824     0   473      +    60  None   470   473   3   \n",
      "0   1  199617  200459     0   841      +    60  None   825   848  23   \n",
      "\n",
      "   is_primary                                              cigar  name  \n",
      "0        True                                    277M1I146M2I47M  S129  \n",
      "0        True  277M1I146M2I62M1D25M1D10M2I7M1I87M2D56M1D31M2D...  CAST  \n",
      "CPU times: user 5.61 ms, sys: 1.86 ms, total: 7.47 ms\n",
      "Wall time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time \n",
    "\n",
    "# #fpath = \"/nfs/turbo/umms-indikar/shared/projects/poreC/pipeline_outputs/population/expanded/annotate/batch02.GRCm39.pe.bam\"\n",
    "# fpath = \"/nfs/turbo/umms-indikar/shared/projects/poreC/pipeline_outputs/population/library/merged.bam\"\n",
    "# bam = pysam.AlignmentFile(fpath)\n",
    "\n",
    "# stop = 1\n",
    "# count = -1\n",
    "\n",
    "# # loop through each monomoner\n",
    "# for read in bam:\n",
    "#     count += 1\n",
    "#     if count == stop:\n",
    "#         break\n",
    "\n",
    "#     # # print the read name\n",
    "#     print(f\"\\n{read.qname=}\")\n",
    "\n",
    "#     # alignment of the monomer both genomes \n",
    "#     seq = read.seq\n",
    "#     h1 = align_monomer(seq, s129_ref, name='S129')\n",
    "#     h2 = align_monomer(seq, cast_ref, name='CAST')\n",
    "\n",
    "#     align = pd.concat([h1, h2])\n",
    "#     print(align)\n",
    "    \n",
    "#     # compare hits (h1 vs. h2)\n",
    "#     # examples:\n",
    "#         # max alignment_score(H1, H2)\n",
    "#         # max alignment_length(H1, H2)\n",
    "#         # min alignment_mismatch(H1, H2)\n",
    "#         # max alignment_quality(H1, H2)\n",
    "    \n",
    "#     # assign --> subread to: h1, h2, or unknown\n",
    "\n",
    "#     # store assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pork",
   "language": "python",
   "name": "pork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
