{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82896810-75bf-4de5-a8bb-8c68595109ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import anndata as an\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "import glob\n",
    "from transformers import BertConfig, BertForMaskedLM, AdamW, DataCollatorForLanguageModeling\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "source_path = os.path.abspath(\"../../source/\")\n",
    "sys.path.append(source_path)\n",
    "import utils as ut\n",
    "import matrix as matrix\n",
    "import centrality as central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafd383c-45c4-4d75-b937-7052dede4375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Number of Cores:\", os.cpu_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a23963-5ca1-455e-94cb-821783fbeac3",
   "metadata": {},
   "source": [
    "# Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf84294c-3f2c-4e7f-b380-b4e4903f649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>size</th>\n",
       "      <th>bp_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279</td>\n",
       "      <td>195154279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>181755017</td>\n",
       "      <td>376909296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>159745316</td>\n",
       "      <td>536654612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>156860686</td>\n",
       "      <td>693515298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>151758149</td>\n",
       "      <td>845273447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom       size   bp_start\n",
       "0     1  195154279  195154279\n",
       "1     2  181755017  376909296\n",
       "2     3  159745316  536654612\n",
       "3     4  156860686  693515298\n",
       "4     5  151758149  845273447"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load chromsizes \n",
    "fpath = \"/scratch/indikar_root/indikar1/shared_data/population/references/GRCm39.chrom.sizes\"\n",
    "chroms = pd.read_csv(fpath, sep='\\t', header=None, names=['chrom', 'size'])\n",
    "chroms = chroms.head(20) # drop unplaced contigs\n",
    "\n",
    "chroms['bp_start'] = chroms['size'].cumsum()\n",
    "\n",
    "chrom_starts = dict(zip(chroms['chrom'].values, chroms['bp_start'].values))\n",
    "\n",
    "chroms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d12f4d1-a05d-4cbb-a3ac-24070041ee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/indikar_root/indikar1/shared_data/population/align_table/batch04.GRCm39.align_table.parquet',\n",
       " '/scratch/indikar_root/indikar1/shared_data/population/align_table/batch02.GRCm39.align_table.parquet',\n",
       " '/scratch/indikar_root/indikar1/shared_data/population/align_table/batch03.GRCm39.align_table.parquet',\n",
       " '/scratch/indikar_root/indikar1/shared_data/population/align_table/batch01.GRCm39.align_table.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpath = \"/scratch/indikar_root/indikar1/shared_data/population/align_table/\"\n",
    "\n",
    "file_list = glob.glob(f\"{dpath}*\")\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24706255-8da2-43fd-aa74-1732bc029f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch04 (4099946, 12)\n",
      "batch02 (419546, 12)\n",
      "batch03 (2192781, 12)\n",
      "batch01 (3726776, 12)\n",
      "df.shape=(10439049, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_name</th>\n",
       "      <th>align_id</th>\n",
       "      <th>chrom</th>\n",
       "      <th>ref_start</th>\n",
       "      <th>ref_end</th>\n",
       "      <th>is_mapped</th>\n",
       "      <th>local_position</th>\n",
       "      <th>chrom_start</th>\n",
       "      <th>global_position</th>\n",
       "      <th>global_bin</th>\n",
       "      <th>basename</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00001eac-9561-4bd2-a272-1b0a475d75e5</td>\n",
       "      <td>2701970</td>\n",
       "      <td>13</td>\n",
       "      <td>21752768</td>\n",
       "      <td>21753106.0</td>\n",
       "      <td>True</td>\n",
       "      <td>21752937.0</td>\n",
       "      <td>1.887824e+09</td>\n",
       "      <td>1.909577e+09</td>\n",
       "      <td>19096</td>\n",
       "      <td>batch04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00001eac-9561-4bd2-a272-1b0a475d75e5</td>\n",
       "      <td>2701974</td>\n",
       "      <td>13</td>\n",
       "      <td>9587846</td>\n",
       "      <td>9588362.0</td>\n",
       "      <td>True</td>\n",
       "      <td>9588104.0</td>\n",
       "      <td>1.887824e+09</td>\n",
       "      <td>1.897412e+09</td>\n",
       "      <td>18975</td>\n",
       "      <td>batch04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00001eac-9561-4bd2-a272-1b0a475d75e5</td>\n",
       "      <td>2701979</td>\n",
       "      <td>13</td>\n",
       "      <td>3847827</td>\n",
       "      <td>3847900.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3847863.0</td>\n",
       "      <td>1.887824e+09</td>\n",
       "      <td>1.891672e+09</td>\n",
       "      <td>18917</td>\n",
       "      <td>batch04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00002cf2-3a39-4d41-b231-75b50a5df98a</td>\n",
       "      <td>246076</td>\n",
       "      <td>5</td>\n",
       "      <td>54958588</td>\n",
       "      <td>54958907.0</td>\n",
       "      <td>True</td>\n",
       "      <td>54958747.0</td>\n",
       "      <td>8.452734e+08</td>\n",
       "      <td>9.002322e+08</td>\n",
       "      <td>9003</td>\n",
       "      <td>batch04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00002cf2-3a39-4d41-b231-75b50a5df98a</td>\n",
       "      <td>246078</td>\n",
       "      <td>5</td>\n",
       "      <td>54733402</td>\n",
       "      <td>54733982.0</td>\n",
       "      <td>True</td>\n",
       "      <td>54733692.0</td>\n",
       "      <td>8.452734e+08</td>\n",
       "      <td>9.000071e+08</td>\n",
       "      <td>9001</td>\n",
       "      <td>batch04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               read_name  align_id chrom  ref_start  \\\n",
       "11  00001eac-9561-4bd2-a272-1b0a475d75e5   2701970    13   21752768   \n",
       "15  00001eac-9561-4bd2-a272-1b0a475d75e5   2701974    13    9587846   \n",
       "20  00001eac-9561-4bd2-a272-1b0a475d75e5   2701979    13    3847827   \n",
       "22  00002cf2-3a39-4d41-b231-75b50a5df98a    246076     5   54958588   \n",
       "24  00002cf2-3a39-4d41-b231-75b50a5df98a    246078     5   54733402   \n",
       "\n",
       "       ref_end  is_mapped  local_position   chrom_start  global_position  \\\n",
       "11  21753106.0       True      21752937.0  1.887824e+09     1.909577e+09   \n",
       "15   9588362.0       True       9588104.0  1.887824e+09     1.897412e+09   \n",
       "20   3847900.0       True       3847863.0  1.887824e+09     1.891672e+09   \n",
       "22  54958907.0       True      54958747.0  8.452734e+08     9.002322e+08   \n",
       "24  54733982.0       True      54733692.0  8.452734e+08     9.000071e+08   \n",
       "\n",
       "    global_bin basename  order  \n",
       "11       19096  batch04      3  \n",
       "15       18975  batch04      3  \n",
       "20       18917  batch04      3  \n",
       "22        9003  batch04      3  \n",
       "24        9001  batch04      3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "\n",
    "resolution = 1e5\n",
    "\n",
    "columns = [\n",
    "    'read_name',\n",
    "    'align_id',\n",
    "    'chrom', \n",
    "    'ref_start', \n",
    "    'ref_end',\n",
    "    'is_mapped',\n",
    "]\n",
    "\n",
    "for fpath in file_list:\n",
    "    basename = os.path.basename(fpath).split(\".\")[0]\n",
    "    tmp = pd.read_parquet(fpath, columns=columns)\n",
    "    \n",
    "    # only mapped monomers\n",
    "    tmp = tmp[tmp['is_mapped']]\n",
    "    \n",
    "    # only chromosomal contigs (no unplaced contigs)\n",
    "    tmp = tmp[tmp['chrom'].isin(chroms['chrom'].values)]\n",
    "    \n",
    "    # compute the midpoint of each alignment\n",
    "    tmp['local_position'] = ((tmp['ref_end'] - tmp['ref_start']) // 2) + tmp['ref_start']\n",
    "    \n",
    "    # convert local coordinates to global bin loci at some resolution\n",
    "    tmp['chrom_start'] = tmp['chrom'].map(chrom_starts)\n",
    "    tmp['global_position'] = tmp['chrom_start'] + tmp['local_position']\n",
    "    tmp['global_bin'] = tmp['global_position'].apply(lambda x: np.ceil(x / resolution))\n",
    "    tmp = tmp[tmp['global_bin'].notna()]\n",
    "    \n",
    "    tmp['basename'] = basename\n",
    "    \n",
    "    # drop duplicate bins per read (only unique monomners in the contact)\n",
    "    tmp = tmp.drop_duplicates(subset=['read_name', 'global_bin'])\n",
    "    tmp['order'] = tmp.groupby('read_name')['global_bin'].transform('nunique')\n",
    "    \n",
    "    # drop all singletons\n",
    "    tmp = tmp[tmp['order'] > 1]\n",
    "    \n",
    "    print(basename, tmp.shape)    \n",
    "    df.append(tmp)\n",
    "\n",
    "df = pd.concat(df)\n",
    "print(f\"{df.shape=}\")\n",
    "df['global_bin'] = df['global_bin'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83aaa06c-b26b-414e-9a26-f7713d0ab9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['global_bin'].nunique()=24666\n",
      "\n",
      "global_bin\n",
      "4755     524824\n",
      "13974    346644\n",
      "10985     45110\n",
      "20161     15817\n",
      "14296     14827\n",
      "          ...  \n",
      "8058         16\n",
      "28009        11\n",
      "28010         7\n",
      "25239         6\n",
      "27557         2\n",
      "Name: count, Length: 24666, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print the total number of bins (tokens) and the most frequent genomic loci\"\"\"\n",
    "print(f\"{df['global_bin'].nunique()=}\")\n",
    "print()\n",
    "print(df['global_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a9ac1e-395b-499c-99e7-658a0330bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom\n",
      "1     1921\n",
      "10    1274\n",
      "11    1190\n",
      "12    1171\n",
      "13    1176\n",
      "14    1217\n",
      "15    1011\n",
      "16     950\n",
      "17     923\n",
      "18     877\n",
      "19     584\n",
      "2     1787\n",
      "3     1567\n",
      "4     1533\n",
      "5     1482\n",
      "6     1465\n",
      "7     1419\n",
      "8     1264\n",
      "9     1214\n",
      "X     1662\n",
      "Name: global_bin, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>chrom_start</th>\n",
       "      <th>global_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279.0</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103408</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279.0</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206712</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279.0</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51175</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279.0</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43221</th>\n",
       "      <td>1</td>\n",
       "      <td>195154279.0</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chrom  chrom_start  global_bin\n",
       "7110       1  195154279.0        1983\n",
       "103408     1  195154279.0        1984\n",
       "206712     1  195154279.0        1985\n",
       "51175      1  195154279.0        1986\n",
       "43221      1  195154279.0        1987"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a bin map, just in case\n",
    "bin_map = df[['chrom', 'chrom_start', 'global_bin']].drop_duplicates()\n",
    "bin_map = bin_map.sort_values(by='global_bin')\n",
    "\n",
    "print(bin_map.groupby('chrom')['global_bin'].nunique().head(20))\n",
    "\n",
    "print()\n",
    "bin_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b1473-3505-48ef-8804-d44b7b2419ba",
   "metadata": {},
   "source": [
    "# structure the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee3d9d1-59f6-4f88-89ca-2106a0428ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(token_list, max_length=12, pad_token=0):\n",
    "    \"\"\"A function to format a token list\"\"\"\n",
    "    \n",
    "    # truncate long\n",
    "    if len(token_list) > max_length:\n",
    "        token_list = token_list[:max_length]\n",
    "    # pad short\n",
    "    else:\n",
    "        short = max_length - len(token_list)\n",
    "        token_list = list(token_list) + ([pad_token] * short)\n",
    "    return list(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec364387-6506-490d-ad7d-b02bb330e93c",
   "metadata": {},
   "source": [
    "# Sample concatemers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef25026-f475-449e-8070-0f6ff89c7491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 1000\n",
    "read_names  = np.random.choice(df['read_name'].unique(), sample_size, replace=False)\n",
    "len(read_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2c46ad-f2a6-4499-9408-34b7d60a7e9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1326b-d0f0-45a6-af97-268e9fcac8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "token_df = []\n",
    "\n",
    "for read_name, group in df.groupby('read_name'):\n",
    "    \n",
    "    input_row = {\n",
    "        'read_name' : read_name,\n",
    "        'input_ids' : format_input(group['global_bin'].to_list(), max_length),\n",
    "        'order' : len(group),\n",
    "        'length' : max_length,\n",
    "        'chroms' : group['chrom'].to_list(),\n",
    "        'n_chroms' : group['chrom'].nunique(),\n",
    "        'basename' : group['basename'].unique()[0],\n",
    "    }\n",
    "    \n",
    "    token_df.append(input_row)\n",
    "    \n",
    "token_df = pd.DataFrame(token_df)\n",
    "print(f\"{token_df.shape=}\")\n",
    "token_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c98af-e637-4269-97c9-d6a369130c2a",
   "metadata": {},
   "source": [
    "# SAMPLE THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe055f7d-7e44-4b14-9e4c-ab858e9b2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE  = 1000\n",
    "sample = token_df.sample(SAMPLE_SIZE).reset_index(drop=True)\n",
    "input_ids = torch.tensor(sample['input_ids'].to_list())\n",
    "input_ids = input_ids.to(torch.float16)\n",
    "\n",
    "print(f\"{input_ids.shape=}\")\n",
    "print(f\"{input_ids.device=}\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(input_ids)\n",
    "data_loader = DataLoader(dataset, batch_size=8) \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7c9c4-418b-494e-ae3a-486a23ab271f",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bc582-f406-4c50-a9cd-84f465f34073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\n--- GPU Cache Cleared ---\\n\")\n",
    "\n",
    "# Configuration Details\n",
    "total_tokens = bin_map['global_bin'].nunique()\n",
    "vocab_size = int(total_tokens + 1)\n",
    "mask_token_id = int(total_tokens + 2)\n",
    "unk_token_id = int(total_tokens + 3)\n",
    "\n",
    "print(f\"Total Unique Tokens: {total_tokens}\")\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Mask Token ID: {mask_token_id}\")\n",
    "print(f\"Unknown Token ID: {unk_token_id}\")\n",
    "\n",
    "# Hyperparameters\n",
    "masking_prob = 0.15\n",
    "learning_rate = 1e-4\n",
    "num_hidden_layers = 2\n",
    "num_attention_heads = 2\n",
    "output_shape = 10\n",
    "num_epochs = 2\n",
    "\n",
    "print(\"\\n--- Model Hyperparameters ---\")\n",
    "print(f\"Masking Probability: {masking_prob}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Number of Hidden Layers: {num_hidden_layers}\")\n",
    "print(f\"Number of Attention Heads: {num_attention_heads}\")\n",
    "print(f\"Output Shape: {output_shape}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\\n\")\n",
    "\n",
    "# Model Configuration\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=output_shape,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    output_hidden_states=True,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    intermediate_size=output_shape * 2,\n",
    "    max_position_embeddings=max_length,\n",
    ")\n",
    "\n",
    "model = BertForMaskedLM(config)\n",
    "print(model)\n",
    "print(\"--- BERT Model Successfully Built ---\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaaf09-54d9-49fc-8e3f-7b7f68962e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking Function with Debugging Prints\n",
    "def apply_masking(batch, mask_token_id=mask_token_id, mlm_probability=masking_prob):\n",
    "    print(\"\\n--- Inside Masking Function ---\")\n",
    "    print(\"Original Batch Shape:\", batch.shape)\n",
    "    labels = batch.clone()\n",
    "\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [\n",
    "        [i == 0 or i == len(b) - 1 for i in range(len(b))] for b in labels.tolist()\n",
    "    ]\n",
    "\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    print(\"Number of Masked Indices:\", masked_indices.sum().item()) \n",
    "\n",
    "    labels[~masked_indices] = -100\n",
    "    batch[masked_indices] = mask_token_id\n",
    "\n",
    "    print(\"Modified Batch Shape:\", batch.shape)\n",
    "    print(\"Labels Shape:\", labels.shape)\n",
    "    print(\"Sample Masked Batch Values:\", batch[0][:10])\n",
    "    print(\"Sample Labels Values:\", labels[0][:10])\n",
    "    return batch, labels\n",
    "\n",
    "\n",
    "# Training Loop with Debugging Prints\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, no_deprecation_warning=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} ---\")  # Print epoch start\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch[0].to(device) \n",
    "        print(\"Batch size:\", batch.shape)  # Check size before masking\n",
    "        print(\"Batch device:\", batch.device)\n",
    "        print(\"Batch type:\", batch.type())\n",
    "        \n",
    "        # Handle OOV tokens (replace with UNK token)\n",
    "        batch[batch >= vocab_size - 1] = unk_token_id\n",
    "        batch, labels = apply_masking(batch) \n",
    "        \n",
    "        batch = batch.to(torch.long)\n",
    "        print(\"Batch type:\", batch.type())\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Batch Loss:\", loss.item()) # Print loss for each batch\n",
    "  \n",
    "    # Print average loss after each epoch\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    print(f\"Average Loss: {average_loss:.4f}\\n\") # Print average loss with higher precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba7e80-88d5-443c-ae25-a4e642e0a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ced39b-9ed5-4098-8a7a-24d7ec7b8d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50ddc7-9268-43e7-8b6d-8a342f9d6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Masking\n",
    "# def apply_masking(batch, mask_token_id=mask_token_id, mlm_probability=masking_prob):\n",
    "#     labels = batch.clone()  \n",
    "#     probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    \n",
    "#     # Create a mask for positions to be masked\n",
    "#     special_tokens_mask = [\n",
    "#         [i == 0 or i == len(b) - 1 for i in range(len(b))] for b in labels.tolist()\n",
    "#     ]\n",
    "#     probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "#     masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "#     labels[~masked_indices] = -100  \n",
    "\n",
    "#     # Replace masked indices with mask token id\n",
    "#     batch[masked_indices] = mask_token_id\n",
    "#     return batch, labels\n",
    "\n",
    "\n",
    "# # Training Loop\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate, no_deprecation_warning=True)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "# model.to(device)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     total_loss = 0.0  # Track total loss for the epoch\n",
    "\n",
    "#     for batch in data_loader:\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Apply masking using our custom function\n",
    "#         batch = batch[0].to(device) \n",
    "        \n",
    "#         # Handle OOV tokens (replace with UNK token)\n",
    "#         batch[batch >= vocab_size - 1] = unk_token_id\n",
    "#         batch, labels = apply_masking(batch)  \n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(batch, labels=labels)\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "#         # Backward pass\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     # Print average loss after each epoch\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Total Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f357fe-1ed7-45a3-a70e-55cc0d76376c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb3d30-6c28-4eb8-b427-831f00e73b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a8efe-e629-4572-acaf-87cc84e51136",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb19ba-9c6d-4fce-8df0-dfd6a115ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7e7e9-1573-41fa-95b7-bf080a57f273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf00a92d-cf03-46d1-84db-bc5ec719af27",
   "metadata": {},
   "source": [
    "# Convert into \"tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c99fa1-4e13-45ed-b1f1-59914e92dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "bin_names = df.T.columns.astype(int).to_numpy()\n",
    "\n",
    "def format_input(token_list, max_length=12, pad_token=0):\n",
    "    \"\"\"A function to format a token list\"\"\"\n",
    "    \n",
    "    # truncate long\n",
    "    if len(token_list) > max_length:\n",
    "        token_list = token_list[:max_length]\n",
    "    # pad short\n",
    "    else:\n",
    "        short = max_length - len(token_list)\n",
    "        token_list = list(token_list) + ([pad_token] * short)\n",
    "    return list(token_list)\n",
    "    \n",
    "\n",
    "tokens = df.T.apply(lambda x: bin_names[np.argwhere(x != 0).ravel()], axis=1)\n",
    "tokens = tokens.reset_index()\n",
    "tokens.columns = ['read_code', 'raw_input']\n",
    "tokens['order'] = tokens['raw_input'].apply(lambda x: len(x))\n",
    "tokens['input_ids'] = tokens['raw_input'].apply(lambda x: format_input(x, max_length=max_length))\n",
    "tokens['length'] = tokens['input_ids'].apply(lambda x: len(x))\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae30ec-49d3-4735-b636-10a48904ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example integer data (already tokenized)\n",
    "input_ids = torch.tensor(tokens['input_ids'].to_list())\n",
    "print(f\"{input_ids.shape=}\")\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(input_ids)\n",
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True) \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86052d42-f278-4361-beed-f7031cdf8d79",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041fc32-6931-430f-bb84-59732beefaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 200\n",
    "mask_token_id = 199\n",
    "unk_token_id = 198\n",
    "masking_prob = 0.15\n",
    "learning_rate = 1e-4\n",
    "num_hidden_layers = 2\n",
    "num_attention_heads = 2\n",
    "output_shape = 10\n",
    "num_epochs = 3\n",
    "\n",
    "print(f\"{vocab_size=}\")\n",
    "\n",
    "# Model Configuration\n",
    "config = BertConfig(\n",
    "    vocab_size=vocab_size, \n",
    "    hidden_size=output_shape,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    output_hidden_states=True,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    intermediate_size=output_shape * 2,\n",
    "    max_position_embeddings=max_length,\n",
    ")\n",
    "\n",
    "model = BertForMaskedLM(config)\n",
    "\n",
    "# Masking\n",
    "def apply_masking(batch, mask_token_id=mask_token_id, mlm_probability=masking_prob):\n",
    "    labels = batch.clone()  \n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    \n",
    "    # Create a mask for positions to be masked\n",
    "    special_tokens_mask = [\n",
    "        [i == 0 or i == len(b) - 1 for i in range(len(b))] for b in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  \n",
    "\n",
    "    # Replace masked indices with mask token id\n",
    "    batch[masked_indices] = mask_token_id\n",
    "    return batch, labels\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0  # Track total loss for the epoch\n",
    "\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Apply masking using our custom function\n",
    "        batch = batch[0].to(device) \n",
    "        \n",
    "        # Handle OOV tokens (replace with UNK token)\n",
    "        batch[batch >= vocab_size - 1] = unk_token_id\n",
    "        batch, labels = apply_masking(batch)  \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print average loss after each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Total Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27323d-e9db-466a-b691-c96fb9afe3b3",
   "metadata": {},
   "source": [
    "# Extract learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30a65e-0ea6-419b-8a77-c89e51c50b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "sample = tokens.sample(sample_size)\n",
    "\n",
    "new_input = torch.tensor(sample['input_ids'].to_list())\n",
    "print(f\"{new_input.shape=}\")\n",
    "\n",
    "# Move to the same device as the model\n",
    "new_input = new_input.to(device)\n",
    "\n",
    "# Get the model's prediction (logits for each masked position)\n",
    "with torch.no_grad():  # No need to track gradients for this\n",
    "    outputs = model(new_input)\n",
    "    \n",
    "embeddings = outputs.hidden_states[-1] \n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce17f40-ad4f-4fe9-9a2b-83284eb22c90",
   "metadata": {},
   "source": [
    "# Loci embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510530a-9d3f-46b4-bbb2-3b5e6676cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i, (_, row) in enumerate(sample.iterrows()):\n",
    "    n = min(row['order'], max_length)\n",
    "    bins = row['raw_input'][:n] # handle raw inputs larger than the max length\n",
    "\n",
    "    mat = embeddings[i, 0:n, :].cpu().detach().numpy()\n",
    "    mat = pd.DataFrame(mat, index=bins)\n",
    "    result.append(mat)\n",
    "\n",
    "result = pd.concat(result)\n",
    "result = result.reset_index(names='loci')\n",
    "\n",
    "# average ovber the loci embeddings\n",
    "result = result.groupby('loci').mean()\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1fde56-b80a-48a8-b878-fed4cb853ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AnnData object\n",
    "adata = an.AnnData(\n",
    "    X=result,\n",
    ")\n",
    "\n",
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution=1)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 12, 3\n",
    "\n",
    "sns.barplot(x=adata.obs_names.astype(int),\n",
    "            y=adata.obs['leiden'].astype(int) + 1,\n",
    "            hue=adata.obs['leiden'].astype(int) + 1,\n",
    "            palette='viridis',\n",
    "            )\n",
    "\n",
    "plt.xticks([])\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e45141-9ed0-4154-8331-9634ff1c46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=adata.obsm['X_umap'][:, 0],\n",
    "    y=adata.obsm['X_umap'][:, 1],\n",
    "    hue=adata.obs.index.astype(int),\n",
    "    style=adata.obs['leiden'],\n",
    "    ec='k',\n",
    "    palette='viridis',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254f5c1-82fe-40f0-be3e-36ba423c240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 12, 3\n",
    "\n",
    "sns.barplot(x=adata.obs_names.astype(int),\n",
    "            y=adata.obsm['X_pca'][:, 0],\n",
    "            )\n",
    "\n",
    "plt.title(\"1st Eigenvector of Embedding Space\")\n",
    "plt.xticks([])\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(x=adata.obs_names.astype(int),\n",
    "            y=adata.obsm['X_pca'][:, 1],\n",
    "            )\n",
    "plt.title(\"2nd Eigenvector of Embedding Space\")\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3d00e-15ef-4e87-b780-4ec4e9fb396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30143a62-caa6-4d98-bdf2-2d63d542f82d",
   "metadata": {},
   "source": [
    "# AB Compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02948359-fde1-497c-9339-90e88b9400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix.clique_expand_incidence(df, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "A = matrix.normalize_oe(matrix.normalize_kr(A).todense())\n",
    "A = np.asarray(A)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(A)\n",
    "X_pca = pca.transform(A)\n",
    "\n",
    "sns.barplot(x=range(len(X_pca)),\n",
    "            y=X_pca[:, 0],\n",
    "            color='C1')\n",
    "\n",
    "plt.title(\"Clique-Expanded, OE Normed Eigenvector\")\n",
    "\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf501c-cd5a-4088-a6b0-cfb901add01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "component = 1\n",
    "comp_vec = adata.obsm['X_pca'][:, component]\n",
    "\n",
    "print(f\"{X_pca[:, 0].shape=}\")\n",
    "print(f\"{comp_vec.shape=}\")\n",
    "\n",
    "scipy.stats.pearsonr(X_pca[:, 0], comp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e92bb2-4644-4a46-a56f-93bef7ae4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix.clique_expand_incidence(df, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "plt.imshow(np.log1p(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a93e1f-958c-4281-b70c-bc1e37b9e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473dd69a-dd11-43e3-adf6-fa002d03ce79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c269f-71a9-459b-aaad-15ef2c11f35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69cd9e-e939-4575-ac02-7118fb127173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87dc0beb-1100-4214-945e-8929d2c7cc98",
   "metadata": {},
   "source": [
    "# hyperedge embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7409d39-a7ea-4f6c-9602-dce31ecbb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneformer-style embeddings for hyperedges\n",
    "edge_embeddings = embeddings.mean(axis=1).cpu().detach().numpy()  \n",
    "print(f\"{edge_embeddings.shape=}\")\n",
    "\n",
    "obs_names = [f\"Obs_{i}\" for i in range(len(edge_embeddings))]\n",
    "sample['obs_names'] = obs_names\n",
    "\n",
    "# Create AnnData object\n",
    "adata = an.AnnData(\n",
    "    X=edge_embeddings,\n",
    "    obs=sample.set_index('obs_names')\n",
    ")\n",
    "\n",
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution=0.1)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"order\", \"leiden\"],\n",
    "    ncols=1,\n",
    "    size=15,\n",
    ")\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb8d27-082c-4332-8c20-7588b2d21151",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.explode('input_ids')['input_ids'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e7a2d-0c32-46d2-8203-1c06f70baa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look a each cluster:\n",
    "\n",
    "for cluster, group in adata.obs.groupby('leiden'):\n",
    "    print(f\"{cluster=}\")\n",
    "    \n",
    "    group = group.explode('input_ids')\n",
    "    group = group[group['input_ids'] != 0]\n",
    "    print(group['input_ids'].value_counts().head(5))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed7a62-b618-4798-adde-e1de558fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = matrix.clique_expand_incidence(df, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "plt.imshow(np.log1p(A))\n",
    "# plt.axvline(x=86, c='r', alpha=0.2, lw=2)\n",
    "# plt.axhline(y=86, c='r', alpha=0.2, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb6f07-f64f-479b-9556-cf5f637c5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just each group\n",
    "\n",
    "# look a each cluster:\n",
    "for cluster, group in adata.obs.groupby('leiden'):\n",
    "    I = ut.list_of_list_to_incidence(group['raw_input'].to_list())\n",
    "    I = pd.DataFrame(I)\n",
    "    I = ut.fill_missing_bins(I, df.index)\n",
    "    print(f\"{I.shape}\")\n",
    "    \n",
    "    A = matrix.clique_expand_incidence(I, zero_diag=False) \n",
    "    plt.imshow(np.log1p(A))\n",
    "    plt.title(f\"{cluster=}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60db17-0b92-48c5-bf5b-05204d2b8f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d786ec-31f4-42c0-9fb5-41c57d2be1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
