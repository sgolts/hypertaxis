{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7effb21-e433-40fc-a0dc-a0caf0db54bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m source_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../source/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(source_path)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mut\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt2\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhypercore\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gget\n",
    "import sklearn.preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from matplotlib_venn import venn2\n",
    "from matplotlib_venn import venn3\n",
    "from scipy import sparse\n",
    "import xgi\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "source_path = os.path.abspath(\"../source/\")\n",
    "sys.path.append(source_path)\n",
    "import utils as ut\n",
    "import plotting as plt2\n",
    "import hypercore as hc\n",
    "import matrix as matrix\n",
    "import centrality as central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7715f-8033-4144-b1f9-2ad7a361706a",
   "metadata": {},
   "source": [
    "# load 1D features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ff7a8-3509-4a10-ade4-9a23cc7af139",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"/scratch/indikar_root/indikar1/shared_data/higher_order/1D_features/\"\n",
    "resolution = \"1000000\"\n",
    "\n",
    "features = []\n",
    "for f in os.listdir(dpath):\n",
    "    if not resolution in f:\n",
    "        continue\n",
    "    dtype = f.split(\"_\")[0]\n",
    "    fpath = f\"{dpath}{f}\"\n",
    "    fdf = pd.read_parquet(fpath)\n",
    "    fdf = fdf.set_index('index')\n",
    "    fdf.columns = [f\"{dtype}_{x}\" for x in fdf.columns]\n",
    "    features.append(fdf)\n",
    "\n",
    "features = pd.concat(features, axis=1)\n",
    "features = features.fillna(0)\n",
    "\n",
    "## feature scaling\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "features_scaled = pd.DataFrame(features_scaled, \n",
    "                               index=features.index, \n",
    "                               columns=features.columns)\n",
    "\n",
    "feature_columns = features.columns # useful later\n",
    "features_scaled = features_scaled.reset_index(names='bin')\n",
    "\n",
    "print(f\"{features_scaled.shape=}\")\n",
    "features_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b3b37-5e75-4cc7-ac06-f214721fb810",
   "metadata": {},
   "source": [
    "# Load the gene information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9713a4f-fb9b-405b-bb22-5bb6143d9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"load pangloadb\"\n",
    "fpath = \"../resources/mESC_pangloadb.csv\"\n",
    "pdf = pd.read_csv(fpath)\n",
    "print(f\"{pdf.shape=}\")\n",
    "print(f\"{pdf['gene_name'].nunique()=}\")\n",
    "print()\n",
    "\n",
    "\"\"\" load gene ontology annotations \"\"\"\n",
    "fpath = \"../resources/stem_cell_population_maintenance.csv\"\n",
    "godf = pd.read_csv(fpath)\n",
    "godf['gene_name'] = godf['gene_name'].str.upper()\n",
    "print(f\"{godf.shape=}\")\n",
    "print(f\"{godf['gene_name'].nunique()=}\")\n",
    "print()\n",
    "\n",
    "\"\"\" load gene expression \"\"\"\n",
    "fpath = \"/scratch/indikar_root/indikar1/shared_data/higher_order/rna/expression.parquet\"\n",
    "exdf = pd.read_parquet(fpath)\n",
    "\n",
    "tpm_columns = [x for x in exdf.columns if \"TPM\" in x]\n",
    "exdf['expression_mean'] = exdf[tpm_columns].mean(axis=1)\n",
    "exdf['gene_name'] = exdf['gene_name'].str.upper()\n",
    "express_map = dict(zip(exdf['gene_name'].values, exdf['expression_mean'].values))\n",
    "\n",
    "exdf = exdf[exdf['expression_mean'] > 0]\n",
    "print(f\"{exdf.shape=}\")\n",
    "print(f\"{exdf['gene_name'].nunique()=}\")\n",
    "\n",
    "\"\"\" Gene locations \"\"\"\n",
    "resolution = 1000000\n",
    "chromosome = \"1\"\n",
    "\n",
    "gene_table_path = \"/scratch/indikar_root/indikar1/shared_data/higher_order/reference/gene_table.parquet\"\n",
    "gdf = pd.read_parquet(gene_table_path)\n",
    "\n",
    "gdf['gene_name'] = gdf['gene_name'].str.upper()\n",
    "\n",
    "gdf = gdf[gdf['Chromosome'] == \"1\"]\n",
    "gdf['bin'] = gdf['midpoint'].apply(lambda x: ut.bin_loci(x, resolution))\n",
    "\n",
    "\n",
    "gdf['is_gene'] = [True] * len(gdf)\n",
    "gdf['is_pt_gene'] = gdf['gene_biotype'] == 'protein_coding'\n",
    "gdf['is_expressed'] = gdf['gene_name'].isin(exdf['gene_name'].values)\n",
    "gdf['expression'] = gdf['gene_name'].map(express_map)\n",
    "gdf['expression'] = gdf['expression'].fillna(0)\n",
    "gdf['expression_log'] = np.log1p(gdf['expression'])\n",
    "gdf['mESC_panglaoDB_marker'] = gdf['gene_name'].isin(pdf['gene_name'].values)\n",
    "gdf['mESC_GO_marker'] = gdf['gene_name'].isin(godf['gene_name'].values)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558129e7-57fa-4433-b728-8fd57bfa226f",
   "metadata": {},
   "source": [
    "# load the population pore-c data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e03ee9d-432c-4376-bcd6-003e3999723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/scratch/indikar_root/indikar1/shared_data/higher_order/population_pore_c/chr1_1000000_incidence.parquet\"\n",
    "\n",
    "df = pd.read_parquet(fpath)\n",
    "print(f\"{df.shape=}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cc565-1ccc-4485-a5e3-cd7feb8b7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_expanded = ut.fill_missing_bins(df, df.index)\n",
    "A = matrix.clique_expand_incidence(core_expanded, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4abdc2-3161-4a8e-b9aa-1b7d37e15446",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcb28f-ef90-4126-ac34-9792c7bfb93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c943c66-6221-479a-9285-850c491e457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the higher order contacts only\n",
    "orders = df.sum(axis=0)\n",
    "print(f\"{orders.mean()=:.2f}\")\n",
    "\n",
    "# get the degree of higher order contacts\n",
    "high_order_idx = np.argwhere(orders.values > 2).ravel()\n",
    "n_higher_order = df.columns[high_order_idx].shape[0]\n",
    "print(f\"Number of higher-order contacts: {n_higher_order}\")\n",
    "\n",
    "H = df[df.columns[high_order_idx]]\n",
    "print(f\"{H.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b2bd4-856d-4c0e-8630-ec4643ccc936",
   "metadata": {},
   "source": [
    "# Unweighetd Centrality (all hyper edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9175b6-3831-4877-a5c3-ae9d7f17c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(central)\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "measures = [\n",
    "    'linear',\n",
    "    'log-exp', \n",
    "    'max',\n",
    "]\n",
    "\n",
    "for func in measures:\n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(df.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({func : ncent,}, index=df.index))\n",
    "    edges.append(pd.DataFrame({func : ecent,}, index=df.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "print(f\"{nodes.shape=}\")\n",
    "print(f\"{edges.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20cbe7-8f17-42a1-95eb-be84ad71d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.merge(nodes, features_scaled)\n",
    "pdf = pdf.set_index('bin')\n",
    "\n",
    "# get correlations\n",
    "corr = pdf.corr().abs()\n",
    "corr = corr[measures]\n",
    "corr = corr.loc[feature_columns]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 3, 3.5\n",
    "\n",
    "sns.heatmap(data=corr,\n",
    "            lw=1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Correlation'},\n",
    "            )\n",
    "\n",
    "plt.title('Unweighted Centrality (All Contacts)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7e3bb-ee9c-45fb-a22f-826f41f89b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 3\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "sns.histplot(data=nodes.melt(id_vars='bin'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[0],\n",
    "             )\n",
    "axs[0].set_title('Node Centrality Distribution')\n",
    "\n",
    "sns.histplot(data=edges.melt(id_vars='read_code'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[1]\n",
    "            )\n",
    "axs[1].set_title('Edge Centrality Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa297171-6df5-49bb-beef-dbe702160be9",
   "metadata": {},
   "source": [
    "# Unweighted centrality, higher order hyperedges only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb6f24-aee0-443f-a708-74efd48d2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(central)\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "measures = [\n",
    "    'linear',\n",
    "    'log-exp', \n",
    "    'max',\n",
    "]\n",
    "\n",
    "for func in measures:\n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(H.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({func : ncent,}, index=H.index))\n",
    "    edges.append(pd.DataFrame({func : ecent,}, index=H.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "print(f\"{nodes.shape=}\")\n",
    "print(f\"{edges.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844a46f4-f5bf-4fe0-976b-1565707a6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.merge(nodes, features_scaled)\n",
    "pdf = pdf.set_index('bin')\n",
    "\n",
    "# get correlations\n",
    "corr = pdf.corr().abs()\n",
    "corr = corr[measures]\n",
    "corr = corr.loc[feature_columns]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 3, 3.5\n",
    "\n",
    "sns.heatmap(data=corr,\n",
    "            lw=1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Correlation'},\n",
    "            )\n",
    "\n",
    "plt.title('Unweighted Centrality (Higher-Order Contacts)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cecd0d-6049-4913-be4c-04baaddf93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 3\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "sns.histplot(data=nodes.melt(id_vars='bin'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[0],\n",
    "             )\n",
    "axs[0].set_title('Node Centrality Distribution')\n",
    "\n",
    "sns.histplot(data=edges.melt(id_vars='read_code'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[1]\n",
    "            )\n",
    "axs[1].set_title('Edge Centrality Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178c35c-8c46-4c81-be54-c733b6bdf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419151fe-259f-48cc-81ef-c323d45af6ff",
   "metadata": {},
   "source": [
    "# Core Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357753d-edde-4849-84b6-79e9a9326636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Based on the above, there is significant information in the low-order contacts\"\"\"\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "measures = [\n",
    "    'linear',\n",
    "    'log-exp', \n",
    "    'max',\n",
    "]\n",
    "\n",
    "for func in measures:\n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(df.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({func : ncent,}, index=df.index))\n",
    "    edges.append(pd.DataFrame({func : ecent,}, index=df.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "print(f\"{nodes.shape=}\")\n",
    "print(f\"{edges.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294df68c-cca6-4898-810d-fd1ada29d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_core(nodes, col='log-exp', threshold=0.9):\n",
    "    \"\"\"\n",
    "    This function extracts a subset of edges based on a specified quantile threshold.\n",
    "\n",
    "    Args:\n",
    "        edges (DataFrame): DataFrame containing edge data.\n",
    "        col (str): The column in 'edges' to use for filtering.\n",
    "        threshold (float): The threshold used for filtering.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A NumPy array containing the 'read_code' values of the filtered edges.\n",
    "    \"\"\"\n",
    "    node_core = nodes[nodes[col] > threshold]\n",
    "    return node_core['bin'].values\n",
    "\n",
    "\n",
    "def get_edge_core(edges, col='log-exp', threshold=0.9):\n",
    "    \"\"\"\n",
    "    This function extracts a subset of edges based on a specified quantile threshold.\n",
    "\n",
    "    Args:\n",
    "        edges (DataFrame): DataFrame containing edge data.\n",
    "        col (str): The column in 'edges' to use for filtering.\n",
    "        threshold (float): The threshold used for filtering.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A NumPy array containing the 'read_code' values of the filtered edges.\n",
    "    \"\"\"\n",
    "    edge_core = edges[edges[col] > threshold]\n",
    "    return edge_core['read_code'].values\n",
    "\n",
    "\n",
    "n_threshold = 0.6\n",
    "e_threshold = 0.9\n",
    "\n",
    "n_col = 'log-exp'\n",
    "e_col = 'log-exp'\n",
    "\n",
    "node_idx = get_node_core(nodes, col=n_col, threshold=n_threshold)\n",
    "edge_idx = get_edge_core(edges, col=e_col, threshold=e_threshold)\n",
    "\n",
    "core = df.loc[node_idx, edge_idx].copy()\n",
    "print(f\"{core.shape=}\")\n",
    "\n",
    "node_params = {\n",
    "    's' : 1,\n",
    "    'ec' : 'k',\n",
    "    'lw' : 1,\n",
    "    'marker' : \".\",\n",
    "    'zorder' : 2,\n",
    "}\n",
    "\n",
    "line_params = {\n",
    "    'lw' : 0.1,\n",
    "    'alpha' : 0.5,\n",
    "    'zorder' : 1,\n",
    "}\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "\n",
    "sample_size = 500\n",
    "plt2.plot_incidence(ut.sort_by_lowest_index(core.T.sample(sample_size).T), \n",
    "                    node_color='k',\n",
    "                    node_params=node_params,\n",
    "                    line_params=line_params)\n",
    "\n",
    "plt.title(f\"The Core: Chromosome 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f9a5d-502b-4b0e-a5dc-dbc7b276ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_expanded = ut.fill_missing_bins(core, df.index)\n",
    "A = matrix.clique_expand_incidence(core_expanded, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "# A = matrix.normalize_oe(A)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sns.heatmap(np.log1p(A), \n",
    "            cmap='plasma',\n",
    "            square=True, \n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Contacts (log)'},\n",
    "           )\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "plt.title('The Core (Clique-Expanded)')\n",
    "plt.ylabel(\"Chromosome 1 Loci (1Mb)\")\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd9811a-5572-41f1-af61-77f3a47c3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fbe30-8fb1-4742-95a3-b62668b48b46",
   "metadata": {},
   "source": [
    "# Core Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890efc37-0049-4e54-8d75-691a22c347e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_res = []\n",
    "node_res = []\n",
    "for func in measures:\n",
    "    for t in np.linspace(0, 1, 100):\n",
    "        e_idx = get_edge_core(edges, col=func, threshold=t)\n",
    "        e_row = {\n",
    "            'Function' : func,\n",
    "            'Threshold' : t,\n",
    "            'Edges' : len(e_idx),\n",
    "        }\n",
    "        edge_res.append(e_row)\n",
    "        \n",
    "        n_idx = get_node_core(nodes, col=func, threshold=t)\n",
    "        n_row = {\n",
    "            'Function' : func,\n",
    "            'Threshold' : t,\n",
    "            'Nodes' : len(n_idx),\n",
    "        }\n",
    "        node_res.append(n_row)\n",
    "        \n",
    "        \n",
    "edge_res = pd.DataFrame(edge_res)\n",
    "node_res = pd.DataFrame(node_res)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 4\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "sns.lineplot(data=node_res, \n",
    "             x='Threshold',\n",
    "             y='Nodes',\n",
    "             hue='Function',\n",
    "             style='Function',\n",
    "             ax=axs[0],\n",
    "            )\n",
    "\n",
    "sns.lineplot(data=edge_res, \n",
    "             x='Threshold',\n",
    "             y='Edges',\n",
    "             hue='Function',\n",
    "             style='Function',\n",
    "             ax=axs[1],\n",
    "            )\n",
    "\n",
    "axs[0].set_title('Nodes in Core by Threshold')\n",
    "axs[1].set_title('Edges in Core by Threshold')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1f6bc-1779-4157-bcfa-86e0f157c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(matrix)\n",
    "\n",
    "def compute_core_metrics(df, nodes, edges, func='log-exp', n_bins=10):\n",
    "    \"\"\"\n",
    "    Computes core metrics for a bipartite graph represented by a dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Bipartite graph adjacency matrix.\n",
    "        nodes (pd.DataFrame): Node metadata with a column specified by 'func'.\n",
    "        edges (pd.DataFrame): Edge metadata with a column specified by 'func'.\n",
    "        func (str, optional): Column name in 'nodes' and 'edges' for thresholding. Defaults to 'log-exp'.\n",
    "        n_bins (int, optional): Number of bins for thresholding. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing computed core metrics.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    n, m = df.shape\n",
    "\n",
    "    for n_t in np.linspace(0, 1, n_bins):\n",
    "        for e_t in np.linspace(0, 1, n_bins):\n",
    "            n_idx = get_node_core(nodes, col=func, threshold=n_t)\n",
    "            e_idx = get_edge_core(edges, col=func, threshold=e_t)\n",
    "\n",
    "            core = df.loc[n_idx, e_idx].copy()\n",
    "\n",
    "            # Check for empty core\n",
    "            if core.empty:\n",
    "                continue  # Skip this iteration if the core is empty\n",
    "\n",
    "            mean_degree = core.sum(axis=1).mean()\n",
    "            mean_order = core.sum(axis=0).mean()\n",
    "\n",
    "            nn, mm = core.shape\n",
    "\n",
    "            # Minimum core size check\n",
    "            if (nn > 2) & (mm > 2):\n",
    "                L = matrix.hypergraph_laplacian(core)\n",
    "                Lnorm = matrix.normalized_hypergraph_laplacian(core)\n",
    "                \n",
    "                # metrics\n",
    "                fiedler_number = matrix.estimate_fiedler(Lnorm)\n",
    "                entropy = matrix.hypergraph_entropy(L)\n",
    "            else:\n",
    "                fiedler_number = 0\n",
    "\n",
    "            row = {\n",
    "                'node_threshold': n_t,\n",
    "                'edge_threshold': e_t,\n",
    "                'n_nodes': nn,\n",
    "                'n_edges': mm,\n",
    "                'core_sum': core.sum().sum(),\n",
    "                'core_shape': core.shape,\n",
    "                'percent_original': core.size / df.size,\n",
    "                'core_density': core.sum().sum() / core.size if core.size > 0 else 0,  # Avoid division by zero\n",
    "                'percent_nodes': nn / n,\n",
    "                'percent_edges': mm / m,\n",
    "                'mean_degree': mean_degree,\n",
    "                'mean_order': mean_order,\n",
    "                'fiedler_number': fiedler_number,\n",
    "                'entropy' : entropy,\n",
    "            }\n",
    "            res.append(row)\n",
    "\n",
    "    res = pd.DataFrame(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def find_optimal_thresholds(metrics, weights):\n",
    "    \"\"\"\n",
    "    Finds the optimal node and edge thresholds in a DataFrame based on a weighted objective function.\n",
    "\n",
    "    Args:\n",
    "        metrics (pd.DataFrame): DataFrame with metrics data (must include columns specified in `weights`).\n",
    "        weights (dict): Dictionary of metric names and their corresponding weights (positive for maximization, negative for minimization).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Row from metrics_df containing the optimal thresholds and corresponding metric values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the weighted objective function dynamically\n",
    "    def weighted_objective(row):\n",
    "        weighted_sum = 0\n",
    "        for metric, weight in weights.items():\n",
    "            weighted_sum += row[metric] * weight\n",
    "        return weighted_sum\n",
    "\n",
    "    # Apply the function and find the optimal row\n",
    "    metrics['weighted_obj'] = metrics.apply(weighted_objective, axis=1)\n",
    "    optimal_row = metrics.sort_values('weighted_obj', ascending=False).iloc[0]\n",
    "    \n",
    "    return optimal_row\n",
    "\n",
    "metrics = compute_core_metrics(df, \n",
    "                               nodes, \n",
    "                               edges, \n",
    "                               func='log-exp',\n",
    "                               n_bins=10)\n",
    "print(f\"{metrics.shape=}\")\n",
    "metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2886856-3856-463e-9070-059f3fdadb7b",
   "metadata": {},
   "source": [
    "# Compute all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d28ee-42ef-43bc-9a7d-3dd2c0cfc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all metrics\n",
    "n_bins = 15\n",
    "\n",
    "all_metrics = {}\n",
    "\n",
    "for func in measures:\n",
    "    print(f\"Working `{func}`...\")\n",
    "    metrics = compute_core_metrics(df, \n",
    "                                   nodes, \n",
    "                                   edges, \n",
    "                                   func=func,\n",
    "                                   n_bins=n_bins,\n",
    "                                  )\n",
    "    \n",
    "    all_metrics[func] = metrics\n",
    "    \n",
    "print('done!')\n",
    "all_metrics['linear'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adbc5a-b41a-4f29-b4a0-531e5d3a4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plt2)\n",
    "\n",
    "x_col = \"edge_threshold\"    \n",
    "y_col = \"node_threshold\"   \n",
    "\n",
    "z_columns = [\n",
    "    # \"percent_original\", \n",
    "    # \"core_density\",\n",
    "    # \"mean_degree\",\n",
    "    # \"mean_order\",\n",
    "    \"fiedler_number\",\n",
    "    \"entropy\",\n",
    "]\n",
    "\n",
    "plot_kwargs = {\n",
    "    'cmap' : 'viridis',\n",
    "}\n",
    "\n",
    "for func in measures:\n",
    "    metrics = all_metrics[func]\n",
    "    \n",
    "    azims = [30, 30]\n",
    "    for i, z_col in enumerate(z_columns):\n",
    "        perspective_kwargs = {\n",
    "            'azim' : azims[i],\n",
    "            'zoom' : 0.8\n",
    "        }\n",
    "        plt2.plot_3d_surface(metrics, \n",
    "                             x_col, \n",
    "                             y_col,\n",
    "                             z_col,\n",
    "                             plot_kwargs, \n",
    "                             perspective_kwargs,\n",
    "                            )\n",
    "        \n",
    "        ax = plt.gca()\n",
    "\n",
    "        # get the maximum value \n",
    "        weights = {\n",
    "            z_col : 1,\n",
    "        }\n",
    "        max_row = find_optimal_thresholds(metrics, weights)\n",
    "        print(max_row.to_markdown(headers=['Feature', 'Value']))\n",
    "\n",
    "        ax.scatter(max_row[x_col], \n",
    "                   max_row[y_col], \n",
    "                   max_row[z_col], \n",
    "                   marker=\"o\", c='r', s=40,\n",
    "                   zorder=2)\n",
    "\n",
    "        plt.title(func.title())\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1803f6-d36e-4a32-bd16-17b25b92f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f3bb9-6a07-4201-9748-16922eeb8d03",
   "metadata": {},
   "source": [
    "# maximizing the fiedler value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df68ccc-d411-4e68-b928-b3717c1f9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'linear'\n",
    "\n",
    "metrics = all_metrics[func]\n",
    "\n",
    "print(f\"{metrics.shape=}\")\n",
    "\n",
    "# get the maximum value \n",
    "weights = {\n",
    "    \"fiedler_number\" : 1,\n",
    "}\n",
    "max_row = find_optimal_thresholds(metrics, weights)\n",
    "print(max_row.to_markdown(headers=['Feature', 'Value']))\n",
    "\n",
    "n_threshold = max_row['node_threshold']\n",
    "e_threshold = max_row['edge_threshold']\n",
    "\n",
    "# actually build the core\n",
    "node_idx = get_node_core(nodes, col=func, threshold=n_threshold)\n",
    "edge_idx = get_edge_core(edges, col=func, threshold=e_threshold)\n",
    "\n",
    "core = df.loc[node_idx, edge_idx].copy()\n",
    "print(f\"{core.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa57f8f-8821-4352-9f42-8867153b3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_params = {\n",
    "    's' : 1,\n",
    "    'ec' : 'k',\n",
    "    'lw' : 1,\n",
    "    'marker' : \".\",\n",
    "    'zorder' : 2,\n",
    "}\n",
    "\n",
    "line_params = {\n",
    "    'lw' : 0.1,\n",
    "    'alpha' : 0.5,\n",
    "    'zorder' : 1,\n",
    "}\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 4\n",
    "\n",
    "plt2.plot_incidence(ut.sort_by_lowest_index(core), \n",
    "                    node_color='k',\n",
    "                    node_params=node_params,\n",
    "                    line_params=line_params)\n",
    "\n",
    "plt.title(f\"The Core: Chromosome 1 (Maximizing Fiedler Value)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76438cd-5605-4ba9-8f3e-ee8cd244c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_expanded = ut.fill_missing_bins(core, df.index)\n",
    "A = matrix.clique_expand_incidence(core_expanded, zero_diag=False) \n",
    "A = A.sort_index(axis=1)\n",
    "A = A.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sns.heatmap(np.log1p(A), \n",
    "            cmap='plasma',\n",
    "            square=True, \n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Contacts (log)'},\n",
    "           )\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "plt.title('The Core (Clique-Expanded)')\n",
    "plt.ylabel(\"Chromosome 1 Loci (1Mb)\")\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0407f3-ca0c-483a-ba43-018c1d46c3fd",
   "metadata": {},
   "source": [
    "# Weighted Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66d15b-7386-46f0-8c14-f68e848db862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4316ff6-06da-42a0-9fe2-5989175a6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define node weights based on expression\n",
    "node_weights = gdf.groupby('bin')['expression'].sum().reindex(df.index)\n",
    "node_weights = node_weights.fillna(0)\n",
    "node_weights = node_weights.values.reshape(-1, 1)\n",
    "\n",
    "print(f\"{node_weights.shape=}\")\n",
    "\n",
    "# define edge wieghts based on order\n",
    "edge_weights = df.sum(axis=0)\n",
    "edge_weights = edge_weights.values.reshape(-1, 1)\n",
    "\n",
    "print(f\"{edge_weights.shape=}\")\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "measures = [\n",
    "    'linear',\n",
    "    'log-exp', \n",
    "    'max',\n",
    "]\n",
    "\n",
    "for func in measures:\n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(df.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            node_weights=node_weights,\n",
    "                                                            # edge_weights=edge_weights,\n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({func : ncent,}, index=df.index))\n",
    "    edges.append(pd.DataFrame({func : ecent,}, index=df.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03d4f4-46df-4e4d-b701-cbe21a15416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 3\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "sns.histplot(data=nodes.melt(id_vars='bin'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[0],\n",
    "             )\n",
    "axs[0].set_title('Node Centrality Distribution')\n",
    "\n",
    "sns.histplot(data=edges.melt(id_vars='read_code'),\n",
    "             bins=51,\n",
    "             kde=True,\n",
    "             x='value',\n",
    "             hue='variable',\n",
    "             ax=axs[1]\n",
    "            )\n",
    "\n",
    "axs[1].set_title('Edge Centrality Distribution')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e5720-ab53-4c93-ba6d-01055e2effc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.merge(nodes, features_scaled)\n",
    "pdf = pdf.set_index('bin')\n",
    "\n",
    "# get correlations\n",
    "corr = pdf.corr().abs()\n",
    "corr = corr[measures]\n",
    "corr = corr.loc[feature_columns]\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 3, 3.5\n",
    "\n",
    "sns.heatmap(data=corr,\n",
    "            lw=1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Correlation'},\n",
    "            )\n",
    "\n",
    "plt.title('Weighted Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eafc27-1aae-46a1-bb2b-452f1ac094e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all metrics\n",
    "n_bins = 20\n",
    "\n",
    "all_metrics = {}\n",
    "\n",
    "for func in measures:\n",
    "    print(f\"Working `{func}`...\")\n",
    "    metrics = compute_core_metrics(df, \n",
    "                                   nodes, \n",
    "                                   edges, \n",
    "                                   func=func,\n",
    "                                   n_bins=n_bins,\n",
    "                                  )\n",
    "    \n",
    "    all_metrics[func] = metrics\n",
    "    \n",
    "all_metrics['linear'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe12b5-396a-44fb-935b-97d5f3100c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plt2)\n",
    "\n",
    "func = 'max'\n",
    "metrics = all_metrics[func]\n",
    "\n",
    "plot_kwargs = {\n",
    "    'cmap' : 'viridis',\n",
    "    'zorder' : 1,\n",
    "}\n",
    "\n",
    "perspective_kwargs = {\n",
    "    'azim' : 30,\n",
    "    'zoom' : 0.8\n",
    "}\n",
    "\n",
    "x_col = \"edge_threshold\"    \n",
    "y_col = \"node_threshold\"   \n",
    "z_col = \"fiedler_number\"\n",
    "  \n",
    "plt2.plot_3d_surface(metrics, \n",
    "                     x_col, \n",
    "                     y_col,\n",
    "                     z_col,\n",
    "                     plot_kwargs, \n",
    "                     perspective_kwargs,\n",
    "                    )\n",
    "ax = plt.gca()\n",
    "\n",
    "# get the maximum value \n",
    "weights = {\n",
    "    z_col : 1,    \n",
    "}\n",
    "\n",
    "optim = find_optimal_thresholds(metrics, weights)\n",
    "print(optim.to_markdown(headers=['Feature', 'Value']))\n",
    "\n",
    "ax.scatter(optim[x_col], \n",
    "           optim[y_col],\n",
    "           optim[z_col],\n",
    "           marker=\"o\", c='r', s=40,\n",
    "           zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7afe59-e443-44fd-9fb0-a592a4901f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'max'\n",
    "metrics = all_metrics[func]\n",
    "\n",
    "\n",
    "weights = {\n",
    "    # 'node_threshold': 1,     # Maximize\n",
    "    'edge_threshold': 0.1,     # Maximize\n",
    "    'fiedler_number': 1,     # Maximize\n",
    "    'percent_original': -1,     # Minimize\n",
    "    # 'entropy': -1,         # Minimize\n",
    "}\n",
    "\n",
    "optim = find_optimal_thresholds(metrics, weights)\n",
    "print(optim.to_markdown())\n",
    "print()\n",
    "\n",
    "node_idx = get_node_core(nodes, col=func, threshold=optim['node_threshold'])\n",
    "edge_idx = get_edge_core(edges, col=func, threshold=optim['edge_threshold'])\n",
    "\n",
    "core = df.loc[node_idx, edge_idx].copy()\n",
    "print(f\"{core.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a8784-ab7f-4b55-a035-bebe00f6caf3",
   "metadata": {},
   "source": [
    "# Workroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4795c-fdc5-4db9-945c-f2cbfef16366",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'linear'\n",
    "\n",
    "# define node weights based on expression\n",
    "node_weight_df = features_scaled.copy()\n",
    "node_weight_df = node_weight_df[node_weight_df['bin'] > 2]\n",
    "node_weight_df = node_weight_df.set_index('bin')\n",
    "print(f\"{node_weight_df.shape=}\")\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "for feature in node_weight_df.columns:\n",
    "    \n",
    "    weight_vector = node_weight_df[feature].fillna(0)\n",
    "    weight_vector = np.log1p(weight_vector)\n",
    "    weight_vector = weight_vector.values.reshape(-1, 1)\n",
    "    \n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(df.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            node_weights=weight_vector,\n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({feature : ncent,}, index=df.index))\n",
    "    edges.append(pd.DataFrame({feature : ecent,}, index=df.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2dba97-bb46-4065-900f-fd6690a97aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = nodes.set_index('bin')\n",
    "\n",
    "Z = linkage(pdf.to_numpy(), method='ward')\n",
    "\n",
    "max_d = 2\n",
    "\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "row_colors = clusters\n",
    "row_colors = plt2.floats_to_colors(row_colors, colormap='tab20b')\n",
    "\n",
    "sns.clustermap(data=pdf.T,\n",
    "               col_colors=row_colors,\n",
    "               col_linkage=Z,\n",
    "               figsize=(15, 7),\n",
    "               cmap='coolwarm',\n",
    "               row_cluster=False)\n",
    "\n",
    "plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c5775-a2b2-4c2d-b0f3-91f8ffd2d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f767783-75e7-4697-bb51-e2345415fd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502abe3-5073-4e05-953d-4b6a2f3c4a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0169ecb-4c91-433e-ad1c-309dce3a40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.merge(nodes, features_scaled)\n",
    "pdf = pdf.set_index('bin')\n",
    "\n",
    "# get correlations\n",
    "corr = pdf.corr().abs()\n",
    "corr = corr[node_weight_df.columns]\n",
    "corr = corr.loc[feature_columns]\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 3, 3.5\n",
    "\n",
    "sns.heatmap(data=corr,\n",
    "            lw=1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Correlation'},\n",
    "            )\n",
    "\n",
    "plt.title('Weighted Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63414cfb-bb1d-4973-ab1b-b86e63cbc434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e909115-5a44-494e-ad9d-61ccf2d7fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f2b24-e072-435f-b944-3bfcd347191f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a3bed-4178-4926-8f47-c968332aec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1f54f6-89dd-43ca-ae36-e9ca5bb1d957",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142ef37-eb8f-41f0-b0b4-65b7fa505885",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40e15c-0033-4e41-a7cc-0884f7914296",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_params = {\n",
    "    's' : 1,\n",
    "    'ec' : 'k',\n",
    "    'lw' : 1,\n",
    "    'marker' : \".\",\n",
    "    'zorder' : 2,\n",
    "}\n",
    "\n",
    "line_params = {\n",
    "    'lw' : 0.1,\n",
    "    'alpha' : 0.5,\n",
    "    'zorder' : 1,\n",
    "}\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 4\n",
    "\n",
    "sample_size = 500\n",
    "plt2.plot_incidence(ut.sort_by_lowest_index(core.T.sample(sample_size).T), \n",
    "                    node_color='k',\n",
    "                    node_params=node_params,\n",
    "                    line_params=line_params)\n",
    "\n",
    "plt.title(f\"The Core: Chromosome 1 (Maximizing Fiedler Value)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422bf48-e6be-4000-aa30-cbb4dbe35beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c5aca-7bb4-46d6-bf65-fbc3ac5befaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ff269-2946-46e1-8b33-86d0cf0b210c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b4cc6-0f8b-42f8-a436-700e94a36b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fa885-c027-4f67-9935-9d0602c14a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed5454-313d-4051-b2bd-40a7e093c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fc7dd-4a87-41ba-883a-af6b997848bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plt2)\n",
    "gdf['in_core'] = gdf['bin'].isin(node_idx)\n",
    "\n",
    "plt2.plot_venn3_from_df(gdf, \n",
    "                   col1='is_tf',\n",
    "                   col2='is_expressed', \n",
    "                   col3='in_core',\n",
    "                   set_labels=['TF', 'Expressed', 'Core']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ad19f-1698-4ba3-be1b-8b02d4d28fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a2ece-fc2d-4af1-aadb-90b3a57c94d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4281a-b2cd-4abb-9eba-633d6da3c20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc84e76-1752-4e69-951d-cf8202ca18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b088a7-3c64-4079-b035-0bfa9e2e44d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f728f7-e91e-49d9-b95a-8291be83006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc62b37-fe0f-4a1c-a593-78e7ae2d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = metrics.loc[metrics['fiedler_number'].idxmax()]\n",
    "n_threshold = max_row['node_threshold']\n",
    "e_threshold = max_row['edge_threshold']\n",
    "\n",
    "print(f\"node_threshold={n_threshold:.3}\")\n",
    "print(f\"edge_threshold={e_threshold:.3}\")\n",
    "\n",
    "node_idx = get_node_core(nodes, col=func, threshold=n_threshold)\n",
    "edge_idx = get_edge_core(edges, col=func, threshold=e_threshold)\n",
    "\n",
    "core = df.loc[node_idx, edge_idx].copy()\n",
    "print(f\"{core.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1215239-e43e-470c-8fcb-5f05bbfc14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(matrix)\n",
    "L = matrix.hypergraph_laplacian(core)\n",
    "\n",
    "\n",
    "def hypergraph_entropy(L):\n",
    "    \"\"\"\n",
    "    Calculates the hypergraph entropy from the hypergraph Laplacian matrix L.\n",
    "\n",
    "    Args:\n",
    "        L (scipy.sparse.csr_matrix): The hypergraph Laplacian matrix as a sparse CSR matrix.\n",
    "\n",
    "    Returns:\n",
    "        float: The hypergraph entropy.\n",
    "    \"\"\"\n",
    "    # Get eigenvalues and eigenvectors of L. For sparse matrices, using `eigsh` is efficient\n",
    "    eigenvalues, _ = scipy.sparse.linalg.eigsh(L, k=L.shape[0]-1, which='SM')\n",
    "\n",
    "    # Ensure proper handling of small or negative values close to zero to avoid numerical issues.\n",
    "    eigenvalues = np.maximum(eigenvalues, 0)\n",
    "\n",
    "    # Normalize eigenvalues. This ensures sum of normalized eigenvalues equals 1\n",
    "    normalized_eigenvalues = eigenvalues / eigenvalues.sum()\n",
    "\n",
    "    # Calculate hypergraph entropy using the formula given in the image\n",
    "    # Note: The `where` condition ensures correct handling of log(0)\n",
    "    entropy = -np.sum(np.where(normalized_eigenvalues > 0, normalized_eigenvalues * np.log(normalized_eigenvalues), 0))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "hypergraph_entropy(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bb097-0c6b-49b9-8821-44d9a965b490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43710f-e441-43a4-903b-f3e288e46f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa721046-7c1f-43bc-a2f5-cc0c92a45819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d4b12-4634-4afc-8689-669e6f09ec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33cfd1df-ad2f-440f-a7b3-8d999869e346",
   "metadata": {},
   "source": [
    "# Genes and the Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3e919-8210-472d-bb35-190b87bc5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plt2)\n",
    "gdf['in_core'] = gdf['bin'].isin(node_idx)\n",
    "\n",
    "plt2.plot_venn3_from_df(gdf, \n",
    "                   col1='is_tf',\n",
    "                   col2='is_expressed', \n",
    "                   col3='in_core',\n",
    "                   set_labels=['TF', 'Expressed', 'Core']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b944af4-ddc1-44f0-9870-154e002b37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4ef22-c8d9-45b3-89ea-e7db1015d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffc6ab-eb96-4bd9-8c39-cbd8bfbd9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to overwrite the core column\n",
    "\n",
    "def plot_venn3_from_df(df, col1, col2, col3, set_labels=None, title=\"Venn Diagram\"):\n",
    "    \"\"\"Plots a 3-way Venn diagram from boolean columns in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the boolean columns.\n",
    "        col1, col2, col3 (str): Names of the columns to use for the Venn diagram.\n",
    "        set_labels (list, optional): Labels for the sets (defaults to column names).\n",
    "        title (str, optional): Title for the Venn diagram.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate values for each region of the Venn diagram\n",
    "    set1 = df[col1].sum()\n",
    "    set2 = df[col2].sum()\n",
    "    set3 = df[col3].sum()\n",
    "    \n",
    "    set1_only = ((df[col1]) & ~(df[col2]) & ~(df[col3])).sum()\n",
    "    set2_only = ((df[col2]) & ~(df[col1]) & ~(df[col3])).sum()\n",
    "    set3_only = ((df[col3]) & ~(df[col1]) & ~(df[col2])).sum()\n",
    "    \n",
    "    set12 = ((df[col1]) & (df[col2]) & ~(df[col3])).sum()\n",
    "    set13 = ((df[col1]) & (df[col3]) & ~(df[col2])).sum()\n",
    "    set23 = ((df[col2]) & (df[col3]) & ~(df[col1])).sum()\n",
    "    \n",
    "    set123 = ((df[col1]) & (df[col2]) & (df[col3])).sum()\n",
    "\n",
    "    # Create the Venn diagram\n",
    "    if set_labels is None:\n",
    "        set_labels = (col1, col2, col3)  # Use column names as default labels\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    venn3(subsets=(set1_only, \n",
    "                   set2_only,\n",
    "                   set12,\n",
    "                   set3_only,\n",
    "                   set13,\n",
    "                   set23, \n",
    "                   set123), set_labels=set_labels)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "gdf['in_core'] = gdf['bin'].isin(node_idx)\n",
    "plot_venn3_from_df(gdf, \n",
    "                   col1='is_tf',\n",
    "                   col2='is_expressed', \n",
    "                   col3='in_core',\n",
    "                   set_labels=['TF', 'Expressed', 'Core']\n",
    "                  )\n",
    "\n",
    "gdf['in_core'] = gdf['bin'].isin(node_idx)\n",
    "\n",
    "plot_venn3_from_df(gdf, \n",
    "                   col1='is_tf',\n",
    "                   col2='is_expressed', \n",
    "                   col3='in_core',\n",
    "                   set_labels=['TF', 'Expressed', 'Core']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a92ce-62a1-448f-a839-4ff9205705b3",
   "metadata": {},
   "source": [
    "# Weighted Centrality\n",
    "\n",
    "Weighted by the gene expression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca6a8d-f81d-422b-8526-8b8fd73937d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_by_bin = gdf.groupby('bin')['expression_log'].sum().reindex(df.index)\n",
    "expression_by_bin = expression_by_bin.fillna(0)\n",
    "expression_by_bin = expression_by_bin.values.reshape(-1, 1)\n",
    "\n",
    "print(f\"{expression_by_bin.shape=}\")\n",
    "\n",
    "reload(central)\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "measures = [\n",
    "    'linear',\n",
    "    'log-exp', \n",
    "    'max',\n",
    "]\n",
    "\n",
    "for func in measures:\n",
    "    ncent, ecent = central.nonlinear_eigenvector_centrality(H.to_numpy(), \n",
    "                                                            function=func, \n",
    "                                                            node_weights=expression_by_bin,\n",
    "                                                            maxiter=1000)\n",
    "    ncent = ut.min_max(ncent)\n",
    "    ecent = ut.min_max(ecent)\n",
    "    nodes.append(pd.DataFrame({func : ncent,}, index=H.index))\n",
    "    edges.append(pd.DataFrame({func : ecent,}, index=H.columns))\n",
    "    \n",
    "nodes = pd.concat(nodes, axis=1).reset_index()\n",
    "edges = pd.concat(edges, axis=1).reset_index()\n",
    "\n",
    "print(f\"{nodes.shape=}\")\n",
    "print(f\"{edges.shape=}\")\n",
    "\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0d975-2709-4e10-9c27-fa57ae4097f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1D features \n",
    "dpath = \"/scratch/indikar_root/indikar1/shared_data/higher_order/1D_features/\"\n",
    "resolution = \"1000000\"\n",
    "\n",
    "features = []\n",
    "for f in os.listdir(dpath):\n",
    "    if not resolution in f:\n",
    "        continue\n",
    "    dtype = f.split(\"_\")[0]\n",
    "    fpath = f\"{dpath}{f}\"\n",
    "    fdf = pd.read_parquet(fpath)\n",
    "    fdf = fdf.set_index('index')\n",
    "    fdf.columns = [f\"{dtype}_{x}\" for x in fdf.columns]\n",
    "    features.append(fdf)\n",
    "\n",
    "features = pd.concat(features, axis=1)\n",
    "features = features.fillna(0)\n",
    "\n",
    "## feature scaling\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "features_scaled = pd.DataFrame(features_scaled, \n",
    "                               index=features.index, \n",
    "                               columns=features.columns)\n",
    "\n",
    "feature_columns = features.columns\n",
    "feature_columns = [x for x in feature_columns if not \"RNA\" in x]\n",
    "\n",
    "features_scaled = features_scaled.reset_index(names='bin')\n",
    "\n",
    "print(f\"{features_scaled.shape=}\")\n",
    "features_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b10f22-4c72-4865-92e8-14bd75f9eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.merge(nodes, features_scaled)\n",
    "pdf = pdf.set_index('bin')\n",
    "\n",
    "# get correlations\n",
    "corr = pdf.corr().abs()\n",
    "corr = corr[measures]\n",
    "corr = corr.loc[feature_columns]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 3, 3.5\n",
    "\n",
    "sns.heatmap(data=corr,\n",
    "            lw=1,\n",
    "            cmap='coolwarm',\n",
    "            annot=True,\n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Correlation'},\n",
    "            )\n",
    "\n",
    "plt.title('Weighted Centrality (by RNA Expression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a0dee-0f20-46a6-a737-e192b260b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d12734-a2ec-465e-843a-b957e48aebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715f47d-e5b1-4a61-8e27-2aa25ba6eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf05107-51d2-4be7-9576-00ef57efdc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a9694-2bed-4bef-a53b-ec0bcbf268c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = 'log-exp'\n",
    "n_bins = 20\n",
    "\n",
    "n, m = df.shape\n",
    "\n",
    "res = []\n",
    "\n",
    "for n_t in np.linspace(0,1, n_bins):\n",
    "    for e_t in np.linspace(0,1, n_bins):\n",
    "        n_idx = get_node_core(nodes, col=func, threshold=n_t)\n",
    "        e_idx = get_edge_core(edges, col=func, threshold=e_t)\n",
    "        \n",
    "        core = df.loc[n_idx, e_idx].copy()\n",
    "\n",
    "        nn, mm = core.shape\n",
    "        \n",
    "        # doesn't make sense for tiny cores.....\n",
    "        if (nn > 3) & (mm > 3):\n",
    "            L = normalized_hypergraph_laplacian(core)\n",
    "            fiedler_number = estimate_fiedler(L)\n",
    "        else:\n",
    "            fiedler_number = 0\n",
    "            \n",
    "        row = {\n",
    "            'node_threshold' : n_t,\n",
    "            'edge_threshold' : e_t,\n",
    "            'n_nodes' : nn,\n",
    "            'n_edges' : mm,\n",
    "            'fiedler_number' : fiedler_number,\n",
    "        }\n",
    "        res.append(row)\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "print(f\"{res.shape=}\")\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a45f3-49d3-4c1a-ab77-21b7a25fd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = res.loc[res['fiedler_number'].idxmax()]\n",
    "n_threshold = max_row['node_threshold']\n",
    "e_threshold = max_row['edge_threshold']\n",
    "\n",
    "print(f\"node_threshold={n_threshold:.3}\")\n",
    "print(f\"edge_threshold={e_threshold:.3}\")\n",
    "\n",
    "node_idx = get_node_core(nodes, col=func, threshold=n_threshold)\n",
    "edge_idx = get_edge_core(edges, col=func, threshold=e_threshold)\n",
    "\n",
    "core = H.loc[node_idx, edge_idx].copy()\n",
    "print(f\"{core.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942b52b-9c60-4ebd-8825-8befd5ee9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_params = {\n",
    "    's' : 1,\n",
    "    'ec' : 'k',\n",
    "    'lw' : 1,\n",
    "    'marker' : \".\",\n",
    "    'zorder' : 2,\n",
    "}\n",
    "\n",
    "line_params = {\n",
    "    'lw' : 0.1,\n",
    "    'alpha' : 0.5,\n",
    "    'zorder' : 1,\n",
    "}\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['figure.figsize'] = 8, 4\n",
    "\n",
    "plt2.plot_incidence(ut.sort_by_lowest_index(core), \n",
    "                    node_color='k',\n",
    "                    node_params=node_params,\n",
    "                    line_params=line_params)\n",
    "\n",
    "plt.title(f\"The Core: Chromosome 1 (Maximizing Fiedler Value)\")\n",
    "plt.show()\n",
    "\n",
    "core_expanded = ut.fill_missing_bins(core, df.index)\n",
    "Acore = matrix.clique_expand_incidence(core_expanded, zero_diag=False) \n",
    "Acore = Acore.sort_index(axis=1)\n",
    "Acore = Acore.sort_index(axis=0)\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "sns.heatmap(np.log1p(Acore), \n",
    "            cmap='plasma',\n",
    "            square=True, \n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Contacts (log)'},\n",
    "           )\n",
    "\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "plt.title('The Core (Clique-Expanded)')\n",
    "plt.ylabel(\"Chromosome 1 Loci (1Mb)\")\n",
    "plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e274e0-1441-4cfc-9119-d1604cd7a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need to overwrite the core column\n",
    "\n",
    "# gdf['in_core'] = gdf['bin'].isin(node_idx)\n",
    "\n",
    "# plot_venn3_from_df(gdf, \n",
    "#                    col1='is_tf',\n",
    "#                    col2='is_expressed', \n",
    "#                    col3='in_core',\n",
    "#                    set_labels=['TF', 'Expressed', 'Core']\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30f6f7-83ed-4422-880c-7a3013df7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc69ffb-7b0b-4d70-ae57-40cfd9d76f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_genes = gdf[gdf['in_core']]\n",
    "core_genes = core_genes[core_genes['gene_biotype'] == 'protein_coding']\n",
    "core_genes = core_genes[core_genes['expression'] > 0]\n",
    "print(f\"{core_genes.shape=}\")\n",
    "\n",
    "print(f\"{core_genes['is_tf'].sum()=}\")\n",
    "print(f\"{core_genes['mESC_panglaoDB_marker'].sum()=}\")\n",
    "print(f\"{core_genes['mESC_GO_marker'].sum()=}\")\n",
    "\n",
    "core_genes = core_genes.sort_values(by='expression', ascending=False)\n",
    "core_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a9317-845b-4152-989e-3f1153b64211",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = 10\n",
    "database = 'celltypes'\n",
    "genes = core_genes['gene_name'].head(n_genes).values\n",
    "print(genes)\n",
    "edf = gget.enrichr(genes, database=database)\n",
    "edf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43156b-937a-43eb-990d-47e3d20f6296",
   "metadata": {},
   "source": [
    "# compare with Hi-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec827e8-e81f-4904-a0ff-19e037f3be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare against population Hi-C\n",
    "fpath = \"/scratch/indikar_root/indikar1/shared_data/higher_order/population_hic/chr1_1000000.parquet\"\n",
    "\n",
    "hic = pd.read_parquet(fpath)\n",
    "A = hic.to_numpy()\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "# drop the telomere\n",
    "A = A[3:, :][:, 3:]\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "Anorm = matrix.normalize_oe(matrix.normalize_kr(A).todense())\n",
    "\n",
    "# correct outliers\n",
    "top = 10\n",
    "row_idx, col_idx = matrix.get_sorted_upper_triangle_indices(Anorm)\n",
    "\n",
    "# update the matrix \n",
    "for i in range(top):\n",
    "    Anorm[row_idx[i], col_idx[i]] = Anorm.mean()\n",
    "\n",
    "print(f\"{A.shape=}\")\n",
    "\n",
    "plt.imshow(np.log1p(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521db63-4891-465c-bf06-5826aae82ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Acore != 0\n",
    "\n",
    "# Apply the mask\n",
    "masked_arr = np.where(Acore != 0, A, 0)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "\n",
    "sns.heatmap(np.log1p(Acore), \n",
    "            cmap='plasma',\n",
    "            square=True, \n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Contacts (log)'},\n",
    "            ax=axs[0]\n",
    "           )\n",
    "\n",
    "axs[0].set_ylabel(\"\")\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_title('The Core')\n",
    "\n",
    "sns.heatmap(np.log1p(masked_arr), \n",
    "            cmap='plasma',\n",
    "            square=True, \n",
    "            cbar_kws={'shrink' : 0.5, 'label' : 'Contacts (log)'},\n",
    "            ax=axs[1]\n",
    "           )\n",
    "\n",
    "axs[1].set_ylabel(\"\")\n",
    "axs[1].set_xlabel(\"\")\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_title('Hi-C')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f0324-16be-45d4-b2f7-33801b2deb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we chose a similar threshold from the Hi-C data?\n",
    "\n",
    "eigenvalues, eigenvector = np.linalg.eigh(Anorm)\n",
    "pc1 = np.ravel(ut.min_max(eigenvector[:, -1]))\n",
    "\n",
    "r, p = scipy.stats.pearsonr(pc1, nodes['log-exp'].values)\n",
    "print(f\"Correlation: {r=:.3f} ({p=:.5f})\")\n",
    "\n",
    "plt.plot(pc1)\n",
    "plt.plot(nodes['log-exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55202c4b-90ae-4360-9164-a1eed8e36821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the nodes based on the same criteria (fiedler value maximimzation)\n",
    "\n",
    "res = []\n",
    "\n",
    "for t in np.linspace(0, 1, n_bins):\n",
    "    node_idx = np.ravel(np.argwhere(pc1 > t))\n",
    "    if len(node_idx) > 3:\n",
    "        core_hic = Anorm[node_idx, :][:, node_idx]\n",
    "        \n",
    "        L = scipy.sparse.csgraph.laplacian(core_hic, normed=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9c800-8d6d-4f61-9282-7312e32e1772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaac242-55b7-439e-82f6-7744096bcc78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdadd6b-0596-4cd5-b951-e3a9c902616c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e612ba54-e313-4bff-8b58-96263b6557a5",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higher_order",
   "language": "python",
   "name": "higher_order"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
